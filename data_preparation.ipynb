{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pengumpulan Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import scipy.io\n",
    "import numpy as np\n",
    "import cv2 as cv\n",
    "from enlighten_inference import EnlightenOnnxModel\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createSubsetList():\n",
    "    \n",
    "    if not os.path.exists(\"subset_list\") :\n",
    "        os.mkdir(\"subset_list\")\n",
    "    \n",
    "    for i in range(15) : \n",
    "        person = f\"{i:02d}\"\n",
    "        data = pd.read_csv(f\"dataset/MPIIGaze/Evaluation Subset/sample list for eye image/p{person}.txt\", sep=\" \", header=None)\n",
    "        data = data[0]\n",
    "        \n",
    "        duplicate =  data.duplicated()\n",
    "        print(\"Duplicate data: \" + str(duplicate.sum()) + \"\\n\")\n",
    "        \n",
    "        data = data.drop_duplicates()\n",
    "        \n",
    "        face_data = pd.read_csv(f\"dataset/MPIIGaze/Evaluation Subset/annotation for face image/p{person}.txt\", sep=\" \", header=None)\n",
    "        \n",
    "        data = pd.merge(data, face_data, on=0, how=\"outer\")\n",
    "        data.columns = ['day/name',0,1,2,3,4,5,6,7,8,9,10,11]\n",
    "        \n",
    "        data[[\"day\", \"filename\"]] = data['day/name'].str.split(\"/\",expand=True)\n",
    "        data.drop(columns=['day/name'], inplace=True)\n",
    "\n",
    "        data = data[['day', 'filename'] + list(data.columns[:-2])]\n",
    "        \n",
    "        data.to_csv(f\"subset_list/p{person}.txt\", index=False, sep=' ', header=[\"day\", 'filename',0,1,2,3,4,5,6,7,8,9,10,11])\n",
    "        \n",
    "# createSubsetList()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_face_images() : \n",
    "\n",
    "    for i in range(15) :\n",
    "        person = f\"p{i:02d}\"\n",
    "        \n",
    "        df = pd.read_csv(f\"subset_list/{person}.txt\", sep=\" \")\n",
    "        \n",
    "        for _,row in df.iterrows() :\n",
    "            day = row[\"day\"]\n",
    "            fn = row[\"filename\"]\n",
    "            \n",
    "            path = f\"dataset/MPIIFaceGaze/{person}/{day}/{fn}\"\n",
    "            res = os.path.exists(path)        \n",
    "            if not res :\n",
    "                print(path)\n",
    "                \n",
    "# check_face_images()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_face_image(image_path, landmarks, margin=40):\n",
    "  image = cv.imread(image_path)\n",
    "  \n",
    "  # Extract facial landmark coordinates\n",
    "  x1, y1, x2, y2, x3, y3, x4, y4, x5, y5, x6, y6 = landmarks\n",
    "  \n",
    "  # Calculate bounding box coordinates with margin clamping\n",
    "  left = max(0, min(x1, x2, x3, x4, x5, x6) - margin)\n",
    "  top = max(0, min(y1, y2, y3, y4, y5, y6) - margin)\n",
    "  right = min(image.shape[1], max(x1, x2, x3, x4, x5, x6) + margin)\n",
    "  bottom = min(image.shape[0], max(y1, y2, y3, y4, y5, y6) + margin)\n",
    "  \n",
    "  # Crop the image based on clamped bounding box\n",
    "  cropped_image = image[top:bottom, left:right]\n",
    "  \n",
    "  # Resize the image to 224x224 pixels (optional)\n",
    "  resized_image = cv.resize(cropped_image, (224, 224))\n",
    "  \n",
    "  return resized_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def organize_data() :\n",
    "    \n",
    "    for i in range(15) :\n",
    "        \n",
    "        person = f\"p{i:02d}\"\n",
    "        \n",
    "        df = pd.read_csv(f'subset_list/{person}.txt', sep=\" \")\n",
    "        \n",
    "        for _, row in list(df.iterrows()):\n",
    "            \n",
    "            day = row[\"day\"]\n",
    "            filename = row[\"filename\"]\n",
    "            \n",
    "            #copy eye images\n",
    "            mat_data = scipy.io.loadmat(f'dataset/MPIIGaze/Data/Normalized/{person}/{day}.mat')\n",
    "            \n",
    "            data = mat_data[\"data\"]\n",
    "            filenames = mat_data[\"filenames\"]\n",
    "            \n",
    "            res =  np.where(filenames == filename)\n",
    "            \n",
    "            index = res[0][0]\n",
    "            \n",
    "            right_eye = data[0][0][0]\n",
    "            left_eye = data[0][0][1]\n",
    "            \n",
    "            \n",
    "            gaze_pos_right = right_eye[0][0][0][index]\n",
    "            gaze_pos_left = left_eye[0][0][0][index]\n",
    "            \n",
    "            right_eye_img = right_eye[0][0][1][index]\n",
    "            left_eye_img = left_eye[0][0][1][index]\n",
    "            \n",
    "            face_img_path = f\"dataset/MPIIFaceGaze/{person}/{day}/{filename}\"\n",
    "            landmarks = row[2:14]\n",
    "            \n",
    "            face_img = get_face_image(face_img_path, landmarks=landmarks)\n",
    "                        \n",
    "            if not os.path.exists(f\"data_subset/original/{person}/{day}\") :\n",
    "                os.makedirs(f\"data_subset/original/{person}/{day}/left_eye\", exist_ok=True)\n",
    "                os.makedirs(f\"data_subset/original/{person}/{day}/right_eye\", exist_ok=True)\n",
    "                os.makedirs(f\"data_subset/original/{person}/{day}/face\", exist_ok=True)\n",
    "            \n",
    "            cv.imwrite(f\"data_subset/original/{person}/{day}/left_eye/{filename}\", left_eye_img)\n",
    "            cv.imwrite(f\"data_subset/original/{person}/{day}/right_eye/{filename}\", right_eye_img)\n",
    "            \n",
    "            with open(f\"data_subset/original/{person}/{day}/data.txt\", \"a\") as file :\n",
    "                file.write(f\"{filename} {gaze_pos_left[0]} {gaze_pos_left[1]} {gaze_pos_left[2]} {gaze_pos_right[0]} {gaze_pos_right[1]} {gaze_pos_right[2]} \\n\")\n",
    "                \n",
    "            cv.imwrite(f\"data_subset/original/{person}/{day}/face/{filename}\", face_img)\n",
    "            \n",
    "            print(f\"{person} {day} {filename} --> Done\")\n",
    "            \n",
    "# organize_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def enhance_img():\n",
    "    model = EnlightenOnnxModel(providers = [\"CPUExecutionProvider\"])\n",
    "\n",
    "    for i in range(15) :\n",
    "        \n",
    "        person = f\"p{i:02d}\"\n",
    "        \n",
    "        df = pd.read_csv(f'subset_list/{person}.txt', sep=\" \")\n",
    "        \n",
    "        for _, row in list(df.iterrows()):\n",
    "            \n",
    "            day = row[\"day\"]\n",
    "            filename = row[\"filename\"]\n",
    "            \n",
    "            l_eye_img = cv.imread(f\"data_subset/original/{person}/{day}/left_eye/{filename}\")\n",
    "            r_eye_img = cv.imread(f\"data_subset/original/{person}/{day}/right_eye/{filename}\")\n",
    "            face_img = cv.imread(f\"data_subset/original/{person}/{day}/face/{filename}\")\n",
    "            \n",
    "            # face_img = cv.cvtColor(face_img, cv.COLOR_BGR2RGB)\n",
    "            \n",
    "            if not os.path.exists(f\"data_subset/enhanced/{person}/{day}\") :\n",
    "                os.makedirs(f\"data_subset/enhanced/{person}/{day}/left_eye\", exist_ok=True)\n",
    "                os.makedirs(f\"data_subset/enhanced/{person}/{day}/right_eye\", exist_ok=True)\n",
    "                os.makedirs(f\"data_subset/enhanced/{person}/{day}/face\", exist_ok=True)\n",
    "                \n",
    "            e_l_eye_img = model.predict(l_eye_img)\n",
    "            e_r_eye_img = model.predict(r_eye_img)\n",
    "            e_face_img = model.predict(face_img)\n",
    "            \n",
    "            e_r_eye_img = cv.cvtColor(e_r_eye_img, cv.COLOR_RGB2GRAY)\n",
    "            e_l_eye_img = cv.cvtColor(e_l_eye_img, cv.COLOR_RGB2GRAY)\n",
    "            \n",
    "            cv.imwrite(f\"data_subset/enhanced/{person}/{day}/left_eye/{filename}\", e_l_eye_img)\n",
    "            cv.imwrite(f\"data_subset/enhanced/{person}/{day}/right_eye/{filename}\", e_r_eye_img)  \n",
    "            cv.imwrite(f\"data_subset/enhanced/{person}/{day}/face/{filename}\", e_face_img)\n",
    "            \n",
    "            \n",
    "            if not (os.path.exists(f\"data_subset/enhanced/{person}/{day}/data.txt\")) :\n",
    "            \n",
    "                # Source and destination file paths\n",
    "                source_file = f\"data_subset/original/{person}/{day}/data.txt\"\n",
    "                destination_file = f\"data_subset/enhanced/{person}/{day}/data.txt\"\n",
    "\n",
    "                # Copy the file\n",
    "                shutil.copy(source_file, destination_file)\n",
    "\n",
    "                print(f\"File copied from '{source_file}' to '{destination_file}'.\")\n",
    "\n",
    "            \n",
    "            print(f\"{person} {day} {filename} --> Done\")\n",
    "            \n",
    "# enhance_img()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
