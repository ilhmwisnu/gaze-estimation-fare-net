{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pengumpulan Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import scipy.io\n",
    "import numpy as np\n",
    "import cv2 as cv\n",
    "from enlighten_inference import EnlightenOnnxModel\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createSubsetList():\n",
    "    \n",
    "    if not os.path.exists(\"subset_list\") :\n",
    "        os.mkdir(\"subset_list\")\n",
    "    \n",
    "    for i in range(15) : \n",
    "        person = f\"{i:02d}\"\n",
    "        data = pd.read_csv(f\"dataset/MPIIGaze/Evaluation Subset/sample list for eye image/p{person}.txt\", sep=\" \", header=None)\n",
    "        data = data[0]\n",
    "        \n",
    "        duplicate =  data.duplicated()\n",
    "        print(\"Duplicate data: \" + str(duplicate.sum()) + \"\\n\")\n",
    "        \n",
    "        data = data.drop_duplicates()\n",
    "        \n",
    "        face_data = pd.read_csv(f\"dataset/MPIIGaze/Evaluation Subset/annotation for face image/p{person}.txt\", sep=\" \", header=None)\n",
    "        \n",
    "        data = pd.merge(data, face_data, on=0, how=\"outer\")\n",
    "        data.columns = ['day/name',0,1,2,3,4,5,6,7,8,9,10,11]\n",
    "        \n",
    "        data[[\"day\", \"filename\"]] = data['day/name'].str.split(\"/\",expand=True)\n",
    "        data.drop(columns=['day/name'], inplace=True)\n",
    "\n",
    "        data = data[['day', 'filename'] + list(data.columns[:-2])]\n",
    "        \n",
    "        data.to_csv(f\"subset_list/p{person}.txt\", index=False, sep=' ', header=[\"day\", 'filename',0,1,2,3,4,5,6,7,8,9,10,11])\n",
    "        \n",
    "# createSubsetList()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_face_images() : \n",
    "\n",
    "    for i in range(15) :\n",
    "        person = f\"p{i:02d}\"\n",
    "        \n",
    "        df = pd.read_csv(f\"subset_list/{person}.txt\", sep=\" \")\n",
    "        \n",
    "        for _,row in df.iterrows() :\n",
    "            day = row[\"day\"]\n",
    "            fn = row[\"filename\"]\n",
    "            \n",
    "            path = f\"dataset/MPIIFaceGaze/{person}/{day}/{fn}\"\n",
    "            res = os.path.exists(path)        \n",
    "            if not res :\n",
    "                print(path)\n",
    "                \n",
    "# check_face_images()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_face_image(image_path, landmarks, margin=40):\n",
    "  image = cv.imread(image_path)\n",
    "  \n",
    "  # Extract facial landmark coordinates\n",
    "  x1, y1, x2, y2, x3, y3, x4, y4, x5, y5, x6, y6 = landmarks\n",
    "  \n",
    "  # Calculate bounding box coordinates with margin clamping\n",
    "  left = max(0, min(x1, x2, x3, x4, x5, x6) - margin)\n",
    "  top = max(0, min(y1, y2, y3, y4, y5, y6) - margin)\n",
    "  right = min(image.shape[1], max(x1, x2, x3, x4, x5, x6) + margin)\n",
    "  bottom = min(image.shape[0], max(y1, y2, y3, y4, y5, y6) + margin)\n",
    "  \n",
    "  # Crop the image based on clamped bounding box\n",
    "  cropped_image = image[top:bottom, left:right]\n",
    "  \n",
    "  # Resize the image to 224x224 pixels (optional)\n",
    "  resized_image = cv.resize(cropped_image, (224, 224))\n",
    "  \n",
    "  return resized_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def organize_data() :\n",
    "    \n",
    "    for i in range(15) :\n",
    "        \n",
    "        person = f\"p{i:02d}\"\n",
    "        \n",
    "        df = pd.read_csv(f'subset_list/{person}.txt', sep=\" \")\n",
    "        \n",
    "        for _, row in list(df.iterrows()):\n",
    "            \n",
    "            day = row[\"day\"]\n",
    "            filename = row[\"filename\"]\n",
    "            \n",
    "            #copy eye images\n",
    "            mat_data = scipy.io.loadmat(f'dataset/MPIIGaze/Data/Normalized/{person}/{day}.mat')\n",
    "            \n",
    "            data = mat_data[\"data\"]\n",
    "            filenames = mat_data[\"filenames\"]\n",
    "            \n",
    "            res =  np.where(filenames == filename)\n",
    "            \n",
    "            index = res[0][0]\n",
    "            \n",
    "            right_eye = data[0][0][0]\n",
    "            left_eye = data[0][0][1]\n",
    "            \n",
    "            gaze_pos_right = right_eye[0][0][0][index]\n",
    "            gaze_pos_left = left_eye[0][0][0][index]\n",
    "            \n",
    "            right_eye_img = right_eye[0][0][1][index]\n",
    "            left_eye_img = left_eye[0][0][1][index]\n",
    "            \n",
    "            face_img_path = f\"dataset/MPIIFaceGaze/{person}/{day}/{filename}\"\n",
    "            landmarks = row[2:14]\n",
    "            \n",
    "            face_img = get_face_image(face_img_path, landmarks=landmarks)\n",
    "                        \n",
    "            if not os.path.exists(f\"data_subset/original/{person}/{day}\") :\n",
    "                os.makedirs(f\"data_subset/original/{person}/{day}/left_eye\", exist_ok=True)\n",
    "                os.makedirs(f\"data_subset/original/{person}/{day}/right_eye\", exist_ok=True)\n",
    "                os.makedirs(f\"data_subset/original/{person}/{day}/face\", exist_ok=True)\n",
    "            \n",
    "            cv.imwrite(f\"data_subset/original/{person}/{day}/left_eye/{filename}\", left_eye_img)\n",
    "            cv.imwrite(f\"data_subset/original/{person}/{day}/right_eye/{filename}\", right_eye_img)\n",
    "            \n",
    "            with open(f\"data_subset/original/{person}/{day}/data.txt\", \"a\") as file :\n",
    "                file.write(f\"{filename} {gaze_pos_left[0]} {gaze_pos_left[1]} {gaze_pos_left[2]} {gaze_pos_right[0]} {gaze_pos_right[1]} {gaze_pos_right[2]} \\n\")\n",
    "                \n",
    "            cv.imwrite(f\"data_subset/original/{person}/{day}/face/{filename}\", face_img)\n",
    "            \n",
    "            print(f\"{person} {day} {filename} --> Done\")\n",
    "            \n",
    "# organize_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def enhance_img():\n",
    "    model = EnlightenOnnxModel(providers = [\"CPUExecutionProvider\"])\n",
    "\n",
    "    for i in range(15) :\n",
    "        \n",
    "        person = f\"p{i:02d}\"\n",
    "        \n",
    "        df = pd.read_csv(f'subset_list/{person}.txt', sep=\" \")\n",
    "        \n",
    "        for _, row in list(df.iterrows()):\n",
    "            \n",
    "            day = row[\"day\"]\n",
    "            filename = row[\"filename\"]\n",
    "            \n",
    "            l_eye_img = cv.imread(f\"data_subset/original/{person}/{day}/left_eye/{filename}\")\n",
    "            r_eye_img = cv.imread(f\"data_subset/original/{person}/{day}/right_eye/{filename}\")\n",
    "            face_img = cv.imread(f\"data_subset/original/{person}/{day}/face/{filename}\")\n",
    "            \n",
    "        \n",
    "            e_l_eye_img = model.predict(l_eye_img)\n",
    "            e_r_eye_img = model.predict(r_eye_img)\n",
    "            e_face_img = model.predict(face_img)\n",
    "            \n",
    "            e_r_eye_img = cv.cvtColor(e_r_eye_img, cv.COLOR_RGB2GRAY)\n",
    "            e_l_eye_img = cv.cvtColor(e_l_eye_img, cv.COLOR_RGB2GRAY)\n",
    "            \n",
    "            if not os.path.exists(f\"data_subset/enhanced/{person}/{day}\") :\n",
    "                os.makedirs(f\"data_subset/enhanced/{person}/{day}/left_eye\", exist_ok=True)\n",
    "                os.makedirs(f\"data_subset/enhanced/{person}/{day}/right_eye\", exist_ok=True)\n",
    "                os.makedirs(f\"data_subset/enhanced/{person}/{day}/face\", exist_ok=True)\n",
    "            \n",
    "            cv.imwrite(f\"data_subset/enhanced/{person}/{day}/left_eye/{filename}\", e_l_eye_img)\n",
    "            cv.imwrite(f\"data_subset/enhanced/{person}/{day}/right_eye/{filename}\", e_r_eye_img)  \n",
    "            cv.imwrite(f\"data_subset/enhanced/{person}/{day}/face/{filename}\", e_face_img)\n",
    "            \n",
    "            \n",
    "            if not (os.path.exists(f\"data_subset/enhanced/{person}/{day}/data.txt\")) :\n",
    "            \n",
    "                # Source and destination file paths\n",
    "                source_file = f\"data_subset/original/{person}/{day}/data.txt\"\n",
    "                destination_file = f\"data_subset/enhanced/{person}/{day}/data.txt\"\n",
    "\n",
    "                # Copy the file\n",
    "                shutil.copy(source_file, destination_file)\n",
    "\n",
    "                print(f\"File copied from '{source_file}' to '{destination_file}'.\")\n",
    "\n",
    "            \n",
    "            print(f\"{person} {day} {filename} --> Done\")\n",
    "            \n",
    "# enhance_img()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def read_this(image_path, gray_scale=False):\n",
    "#     image_src = cv.imread(image_path)\n",
    "#     if gray_scale:\n",
    "#         image_src = cv.cvtColor(image_src, cv.COLOR_BGR2GRAY)\n",
    "#     else:\n",
    "#         image_src = cv.cvtColor(image_src, cv.COLOR_BGR2RGB)\n",
    "#     return image_src\n",
    "\n",
    "# def equalize_img(image_path, with_plot=False, gray_scale=False):\n",
    "#     image_src = read_this(image_path=image_path, gray_scale=gray_scale)\n",
    "#     if not gray_scale:\n",
    "#         r_image, g_image, b_image = cv.split(image_src)\n",
    "\n",
    "#         r_image_eq = cv.equalizeHist(r_image)\n",
    "#         g_image_eq = cv.equalizeHist(g_image)\n",
    "#         b_image_eq = cv.equalizeHist(b_image)\n",
    "\n",
    "#         image_eq = cv.merge((r_image_eq, g_image_eq, b_image_eq))\n",
    "#         cmap_val = None\n",
    "#     else:\n",
    "#         image_eq = cv.equalizeHist(image_src)\n",
    "#         cmap_val = 'gray'\n",
    "\n",
    "#     if with_plot:\n",
    "#         fig = plt.figure(figsize=(10, 20))\n",
    "\n",
    "#         ax1 = fig.add_subplot(2, 2, 1)\n",
    "#         ax1.axis(\"off\")\n",
    "#         ax1.title.set_text('Original')\n",
    "#         ax2 = fig.add_subplot(2, 2, 2)\n",
    "#         ax2.axis(\"off\")\n",
    "#         ax2.title.set_text(\"Equalized\")\n",
    "\n",
    "#         ax1.imshow(image_src, cmap=cmap_val)\n",
    "#         ax2.imshow(image_eq, cmap=cmap_val)\n",
    "#         return True\n",
    "#     return image_eq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def enhance_img2():\n",
    "#     for i in range(15) :\n",
    "        \n",
    "#         person = f\"p{i:02d}\"\n",
    "        \n",
    "#         df = pd.read_csv(f'subset_list/{person}.txt', sep=\" \")\n",
    "        \n",
    "#         for _, row in list(df.iterrows()):\n",
    "            \n",
    "#             day = row[\"day\"]\n",
    "#             filename = row[\"filename\"]\n",
    "\n",
    "#             e_l_eye_img = equalize_img(f\"data_subset/enhanced/{person}/{day}/left_eye/{filename}\")\n",
    "#             e_r_eye_img = equalize_img(f\"data_subset/enhanced/{person}/{day}/right_eye/{filename}\")\n",
    "            \n",
    "#             e_r_eye_img = cv.cvtColor(e_r_eye_img, cv.COLOR_RGB2GRAY)\n",
    "#             e_l_eye_img = cv.cvtColor(e_l_eye_img, cv.COLOR_RGB2GRAY)\n",
    "            \n",
    "#             if not os.path.exists(f\"data_subset/enhanced2/{person}/{day}\") :\n",
    "#                 os.makedirs(f\"data_subset/enhanced2/{person}/{day}/left_eye\", exist_ok=True)\n",
    "#                 os.makedirs(f\"data_subset/enhanced2/{person}/{day}/right_eye\", exist_ok=True)\n",
    "#                 os.makedirs(f\"data_subset/enhanced2/{person}/{day}/face\", exist_ok=True)\n",
    "            \n",
    "#             cv.imwrite(f\"data_subset/enhanced2/{person}/{day}/left_eye/{filename}\", e_l_eye_img)\n",
    "#             cv.imwrite(f\"data_subset/enhanced2/{person}/{day}/right_eye/{filename}\", e_r_eye_img) \n",
    "            \n",
    "#             shutil.copy(f\"data_subset/enhanced/{person}/{day}/face/{filename}\", f\"data_subset/enhanced2/{person}/{day}/face/{filename}\")\n",
    "            \n",
    "    \n",
    "            \n",
    "            \n",
    "#             if not (os.path.exists(f\"data_subset/enhanced2/{person}/{day}/data.txt\")) :\n",
    "            \n",
    "#                 # Source and destination file paths\n",
    "#                 source_file = f\"data_subset/original/{person}/{day}/data.txt\"\n",
    "#                 destination_file = f\"data_subset/enhanced2/{person}/{day}/data.txt\"\n",
    "\n",
    "#                 # Copy the file\n",
    "#                 shutil.copy(source_file, destination_file)\n",
    "\n",
    "#                 print(f\"File copied from '{source_file}' to '{destination_file}'.\")\n",
    "\n",
    "            \n",
    "#             print(f\"{person} {day} {filename} --> Done\")\n",
    "            \n",
    "# # enhance_img2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def enhance_contrast(image_path, is_grayscale=False, clip_limit=2.0, tile_grid_size=(8, 8)):\n",
    "#     # Read the image\n",
    "#     if is_grayscale:\n",
    "#         image = cv.imread(image_path, cv.IMREAD_GRAYSCALE)\n",
    "#         if image is None:\n",
    "#             print(f\"Error: Unable to open image file: {image_path}\")\n",
    "#             return None\n",
    "        \n",
    "#         # Apply CLAHE to the grayscale image\n",
    "#         clahe = cv.createCLAHE(clipLimit=clip_limit, tileGridSize=tile_grid_size)\n",
    "#         enhanced_image = clahe.apply(image)\n",
    "    \n",
    "#     else:\n",
    "#         image = cv.imread(image_path)\n",
    "#         if image is None:\n",
    "#             print(f\"Error: Unable to open image file: {image_path}\")\n",
    "#             return None\n",
    "        \n",
    "#         # Convert the image to LAB color space\n",
    "#         lab = cv.cvtColor(image, cv.COLOR_BGR2LAB)\n",
    "        \n",
    "#         # Split the LAB image to different channels\n",
    "#         l, a, b = cv.split(lab)\n",
    "        \n",
    "#         # Apply CLAHE to the L-channel\n",
    "#         clahe = cv.createCLAHE(clipLimit=clip_limit, tileGridSize=tile_grid_size)\n",
    "#         cl = clahe.apply(l)\n",
    "        \n",
    "#         # Merge the CLAHE enhanced L-channel back with A and B channels\n",
    "#         limg = cv.merge((cl, a, b))\n",
    "        \n",
    "#         # Convert the LAB image back to RGB color space\n",
    "#         enhanced_image = cv.cvtColor(limg, cv.COLOR_LAB2BGR)\n",
    "    \n",
    "#     return enhanced_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def enhance_img3(): # CLAHE\n",
    "#     for i in range(15) :\n",
    "        \n",
    "#         person = f\"p{i:02d}\"\n",
    "        \n",
    "#         df = pd.read_csv(f'subset_list/{person}.txt', sep=\" \")\n",
    "        \n",
    "#         for _, row in list(df.iterrows()):\n",
    "            \n",
    "#             day = row[\"day\"]\n",
    "#             filename = row[\"filename\"]\n",
    "\n",
    "#             e_l_eye_img = enhance_contrast(f\"data_subset/enhanced/{person}/{day}/left_eye/{filename}\", is_grayscale=True)\n",
    "#             e_r_eye_img = enhance_contrast(f\"data_subset/enhanced/{person}/{day}/right_eye/{filename}\", is_grayscale=True)\n",
    "#             e_face_img = enhance_contrast(f\"data_subset/enhanced/{person}/{day}/face/{filename}\")\n",
    "            \n",
    "#             if not os.path.exists(f\"data_subset/enhanced3/{person}/{day}\") :\n",
    "#                 os.makedirs(f\"data_subset/enhanced3/{person}/{day}/left_eye\", exist_ok=True)\n",
    "#                 os.makedirs(f\"data_subset/enhanced3/{person}/{day}/right_eye\", exist_ok=True)\n",
    "#                 os.makedirs(f\"data_subset/enhanced3/{person}/{day}/face\", exist_ok=True)\n",
    "            \n",
    "#             cv.imwrite(f\"data_subset/enhanced3/{person}/{day}/left_eye/{filename}\", e_l_eye_img)\n",
    "#             cv.imwrite(f\"data_subset/enhanced3/{person}/{day}/right_eye/{filename}\", e_r_eye_img)  \n",
    "#             cv.imwrite(f\"data_subset/enhanced3/{person}/{day}/face/{filename}\", e_face_img)\n",
    "            \n",
    "            \n",
    "#             if not (os.path.exists(f\"data_subset/enhanced3/{person}/{day}/data.txt\")) :\n",
    "            \n",
    "#                 # Source and destination file paths\n",
    "#                 source_file = f\"data_subset/original/{person}/{day}/data.txt\"\n",
    "#                 destination_file = f\"data_subset/enhanced3/{person}/{day}/data.txt\"\n",
    "\n",
    "#                 # Copy the file\n",
    "#                 shutil.copy(source_file, destination_file)\n",
    "\n",
    "#                 print(f\"File copied from '{source_file}' to '{destination_file}'.\")\n",
    "\n",
    "            \n",
    "#             print(f\"{person} {day} {filename} --> Done\")\n",
    "            \n",
    "# # enhance_img3()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
